{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEALTH INSURANCE LEAD PREDICTION ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE LIBRARIES\n",
    "import numpy as np # for numerical computation\n",
    "import pandas as pd # for data manipulation\n",
    "import matplotlib.pyplot as plt  # for data visualization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('Machine Problem 1_Rebanal_Princess_Girly_ECE 649_OriginalDataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "# print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Encoding the Categorical Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Handling missing values for categorical features by filling with mode\n",
    "dataset['Health Indicator'].fillna(dataset['Health Indicator'].mode()[0], inplace=True)\n",
    "dataset['Holding_Policy_Duration'].fillna(dataset['Holding_Policy_Duration'].mode()[0], inplace=True)\n",
    "dataset['Holding_Policy_Type'].fillna(dataset['Holding_Policy_Type'].mode()[0], inplace=True)\n",
    "\n",
    "# Defining features and target variable\n",
    "X = dataset.drop(columns=['ID', 'Response'])\n",
    "y = dataset['Response']\n",
    "\n",
    "# List of categorical columns for one-hot encoding\n",
    "categorical_features = ['City_Code', 'Accomodation_Type', 'Reco_Insurance_Type', \n",
    "                        'Is_Spouse', 'Health Indicator', 'Holding_Policy_Duration']\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), [col for col in X.columns if col not in categorical_features])\n",
    "    ])\n",
    "\n",
    "# Creating a pipeline to handle preprocessing\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Applying preprocessing to the features\n",
    "X = pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "# print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Handling missing values for categorical features by filling with mode\n",
    "dataset['Health Indicator'].fillna(dataset['Health Indicator'].mode()[0], inplace=True)\n",
    "dataset['Holding_Policy_Duration'].fillna(dataset['Holding_Policy_Duration'].mode()[0], inplace=True)\n",
    "dataset['Holding_Policy_Type'].fillna(dataset['Holding_Policy_Type'].mode()[0], inplace=True)\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['City_Code'] = label_encoder.fit_transform(dataset['City_Code'])\n",
    "dataset['Accomodation_Type'] = label_encoder.fit_transform(dataset['Accomodation_Type'])\n",
    "dataset['Reco_Insurance_Type'] = label_encoder.fit_transform(dataset['Reco_Insurance_Type'])\n",
    "dataset['Is_Spouse'] = label_encoder.fit_transform(dataset['Is_Spouse'])\n",
    "dataset['Health Indicator'] = label_encoder.fit_transform(dataset['Health Indicator'])\n",
    "dataset['Holding_Policy_Duration'] = label_encoder.fit_transform(dataset['Holding_Policy_Duration'])\n",
    "\n",
    "# print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Splitting the Dataset into Training Dataset & Testing Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 40705 samples\n",
      "Testing set size: 10177 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Testing set size: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Perform Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print('Feature scaling completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Perform SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 30954, 1: 9751})\n",
      "Before Counter({0: 28363, 1: 28363})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print(\"Before\", counter)\n",
    "# \n",
    "# sm = SMOTE(random_state=42)\n",
    "# sm = ADASYN(random_state=42)\n",
    "sm = SMOTETomek(random_state=42)\n",
    "# sm = SMOTEENN()\n",
    "\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_sm)\n",
    "print(\"Before\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2. BUILDING THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_91\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_91\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_252 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_253 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_254 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_252 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_253 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_254 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109</span> (436.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109\u001b[0m (436.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109</span> (436.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109\u001b[0m (436.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=6, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=3, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Importing the Keras Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Initializing the ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Adding the Input Layer and the First Hidden Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Input(shape=(X_train.shape[1],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Adding the Second Hidden Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Adding the Output Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3. TRAINING THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Compiling the ANN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Summarizing the ANN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_78\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_78\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_226 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_225 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_226 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fitting the ANN Model on the Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 568us/step - accuracy: 0.5058 - loss: 461.4499\n",
      "Epoch 2/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.5058 - loss: 0.7785\n",
      "Epoch 3/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.5018 - loss: 0.7588\n",
      "Epoch 4/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.4968 - loss: 0.7354\n",
      "Epoch 5/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.4951 - loss: 0.7313\n",
      "Epoch 6/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.4980 - loss: 0.7054\n",
      "Epoch 7/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.4989 - loss: 0.6959\n",
      "Epoch 8/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.4973 - loss: 0.6936\n",
      "Epoch 9/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.4982 - loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.4916 - loss: 0.6932\n",
      "Epoch 11/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.4973 - loss: 0.6932\n",
      "Epoch 12/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.4955 - loss: 0.6932\n",
      "Epoch 13/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.4991 - loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.4938 - loss: 0.6932\n",
      "Epoch 15/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.5018 - loss: 0.6932\n",
      "Epoch 16/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.5015 - loss: 0.6932\n",
      "Epoch 17/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.5014 - loss: 0.6932\n",
      "Epoch 18/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.4997 - loss: 0.6932\n",
      "Epoch 19/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.4959 - loss: 0.6932\n",
      "Epoch 20/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.5028 - loss: 0.6932\n",
      "Epoch 21/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.5004 - loss: 0.6932\n",
      "Epoch 22/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.4965 - loss: 0.6932\n",
      "Epoch 23/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.5043 - loss: 0.6931\n",
      "Epoch 24/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.4944 - loss: 0.6932\n",
      "Epoch 25/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.4995 - loss: 0.6932\n",
      "Epoch 26/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.5001 - loss: 0.6932\n",
      "Epoch 27/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.4962 - loss: 0.6932\n",
      "Epoch 28/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.4936 - loss: 0.6932\n",
      "Epoch 29/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.5022 - loss: 0.6932\n",
      "Epoch 30/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.4989 - loss: 0.6932\n",
      "Epoch 31/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.4990 - loss: 0.6932\n",
      "Epoch 32/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.5054 - loss: 0.6931\n",
      "Epoch 33/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.4982 - loss: 0.6932\n",
      "Epoch 34/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.4972 - loss: 0.6932\n",
      "Epoch 35/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.4953 - loss: 0.6932\n",
      "Epoch 36/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.5006 - loss: 0.6932\n",
      "Epoch 37/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.5018 - loss: 0.6932\n",
      "Epoch 38/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.5014 - loss: 0.6932\n",
      "Epoch 39/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739us/step - accuracy: 0.4997 - loss: 0.6932\n",
      "Epoch 40/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.4942 - loss: 0.6932\n",
      "Epoch 41/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.4986 - loss: 0.6932\n",
      "Epoch 42/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.5005 - loss: 0.6932\n",
      "Epoch 43/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.4965 - loss: 0.6932\n",
      "Epoch 44/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.5023 - loss: 0.6932\n",
      "Epoch 45/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.4991 - loss: 0.6932\n",
      "Epoch 46/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.4965 - loss: 0.6932\n",
      "Epoch 47/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.4986 - loss: 0.6932\n",
      "Epoch 48/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.4976 - loss: 0.6932\n",
      "Epoch 49/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.5039 - loss: 0.6932\n",
      "Epoch 50/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.4936 - loss: 0.6932\n",
      "Epoch 51/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.4944 - loss: 0.6932\n",
      "Epoch 52/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.5003 - loss: 0.6932\n",
      "Epoch 53/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.5010 - loss: 0.6931\n",
      "Epoch 54/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.4978 - loss: 0.6932\n",
      "Epoch 55/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.4980 - loss: 0.6932\n",
      "Epoch 56/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.4974 - loss: 0.6932\n",
      "Epoch 57/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.4986 - loss: 0.6932\n",
      "Epoch 58/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.4940 - loss: 0.6932\n",
      "Epoch 59/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.5014 - loss: 0.6932\n",
      "Epoch 60/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.5026 - loss: 0.6932\n",
      "Epoch 61/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.4989 - loss: 0.6932\n",
      "Epoch 62/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.4993 - loss: 0.6932\n",
      "Epoch 63/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5027 - loss: 0.6931\n",
      "Epoch 64/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.5028 - loss: 0.6931\n",
      "Epoch 65/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.5024 - loss: 0.6932\n",
      "Epoch 66/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.4951 - loss: 0.6932\n",
      "Epoch 67/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.5021 - loss: 0.6932\n",
      "Epoch 68/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - accuracy: 0.4945 - loss: 0.6932\n",
      "Epoch 69/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.4926 - loss: 0.6932\n",
      "Epoch 70/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.5023 - loss: 0.6932\n",
      "Epoch 71/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step - accuracy: 0.5018 - loss: 0.6932\n",
      "Epoch 72/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.4970 - loss: 0.6932\n",
      "Epoch 73/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.5044 - loss: 0.6932\n",
      "Epoch 74/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.4967 - loss: 0.6932\n",
      "Epoch 75/100\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.5024 - loss: 0.6931\n",
      "Epoch 76/100\n",
      "\u001b[1m1671/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.5009 - loss: 0.6932"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sm, y_train_sm, batch_size=32, epochs=100)\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4. MAKING PREDICTIONS AND EVALUATING THE ANN MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Predicting the Output of the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. To Generate and Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Computing the Hold-Out Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.6752 - loss: 0.6459\n",
      "Hold-Out Accuracy: 0.6726933121681213\n"
     ]
    }
   ],
   "source": [
    "hold_out_accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Hold-Out Accuracy: {hold_out_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Generating the Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      7719\n",
      "           1       0.26      0.20      0.23      2458\n",
      "\n",
      "    accuracy                           0.67     10177\n",
      "   macro avg       0.51      0.51      0.51     10177\n",
      "weighted avg       0.64      0.67      0.66     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr = classification_report(y_test, y_pred,zero_division=0)\n",
    "print(\"Classification Report:\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Predicting the Output of the Single Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Details of the single observation:\n",
      "ID                             1.0\n",
      "City_Code                     22.0\n",
      "Region_Code                 3213.0\n",
      "Accomodation_Type              1.0\n",
      "Reco_Insurance_Type            0.0\n",
      "Upper_Age                     36.0\n",
      "Lower_Age                     36.0\n",
      "Is_Spouse                      0.0\n",
      "Health Indicator               0.0\n",
      "Holding_Policy_Duration        5.0\n",
      "Holding_Policy_Type            3.0\n",
      "Reco_Policy_Cat               22.0\n",
      "Reco_Policy_Premium        11628.0\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Prediction for the single observation: 0\n"
     ]
    }
   ],
   "source": [
    "single_observation_index = 0\n",
    "single_observation = X_test[single_observation_index].reshape(1, -1)\n",
    "\n",
    "single_pred = (model.predict(single_observation) > 0.5).astype(\"int32\")\n",
    "\n",
    "single_observation_details = dataset.iloc[single_observation_index, :-1]\n",
    "\n",
    "print(\"Details of the single observation:\")\n",
    "print(single_observation_details)\n",
    "\n",
    "print(f\"\\nPrediction for the single observation: {single_pred[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5: PERFORM K-FOLD CROSS-VALIDATION TO ASSESS THE PERFORMANCE OF THE ANN MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. To Feature Scale the X Variable Using the StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X.copy()\n",
    "X_standard = sc.fit_transform(X_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Build the ANN Classifier Using the KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Function to build the ANN model\n",
    "def build_classifier():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(X_train_sm.shape[1],)))\n",
    "    model.add(Dense(units=6, activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the Keras classifier\n",
    "classifier = KerasClassifier(model=build_classifier, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Import the **StratifiedKFold** Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Import the **cross_val_score** Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Perform the k-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.1 Using **Accuracy** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7365 - loss: 0.5838\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7594 - loss: 0.5501\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7602 - loss: 0.5459\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7598 - loss: 0.5439\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.7595 - loss: 0.5439\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7581 - loss: 0.5451\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7589 - loss: 0.5436\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.7590 - loss: 0.5444\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7582 - loss: 0.5434\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7591 - loss: 0.5439\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7602 - loss: 0.5423\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.7593 - loss: 0.5428\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7586 - loss: 0.5442\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7621 - loss: 0.5400\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7599 - loss: 0.5422\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7618 - loss: 0.5398\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.7601 - loss: 0.5417\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7567 - loss: 0.5453\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.7619 - loss: 0.5400\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7621 - loss: 0.5386\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7582 - loss: 0.5437\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7601 - loss: 0.5408\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.7595 - loss: 0.5419\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7591 - loss: 0.5428\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7611 - loss: 0.5403\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - accuracy: 0.7603 - loss: 0.5399\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7571 - loss: 0.5441\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7613 - loss: 0.5395\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7603 - loss: 0.5414\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7538 - loss: 0.5479\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7614 - loss: 0.5398\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7583 - loss: 0.5452\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7581 - loss: 0.5437\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - accuracy: 0.7622 - loss: 0.5398\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7599 - loss: 0.5422\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.7625 - loss: 0.5390\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7572 - loss: 0.5436\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7557 - loss: 0.5459\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7572 - loss: 0.5443\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7608 - loss: 0.5399\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7608 - loss: 0.5408\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.7606 - loss: 0.5410\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.7570 - loss: 0.5432\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.7586 - loss: 0.5419\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.7629 - loss: 0.5367\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7590 - loss: 0.5423\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.7610 - loss: 0.5395\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.7630 - loss: 0.5382\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7613 - loss: 0.5403\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7601 - loss: 0.5411\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7593 - loss: 0.5403\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step - accuracy: 0.7602 - loss: 0.5395\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7575 - loss: 0.5432\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7600 - loss: 0.5403\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.7561 - loss: 0.5455\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7625 - loss: 0.5368\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7604 - loss: 0.5404\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.7589 - loss: 0.5413\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7581 - loss: 0.5421\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.7561 - loss: 0.5441\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step - accuracy: 0.7590 - loss: 0.5399\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7630 - loss: 0.5365\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7628 - loss: 0.5355\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - accuracy: 0.7598 - loss: 0.5404\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7620 - loss: 0.5380\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7608 - loss: 0.5388\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7588 - loss: 0.5408\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7618 - loss: 0.5366\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - accuracy: 0.7607 - loss: 0.5381\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7603 - loss: 0.5392\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.7604 - loss: 0.5383\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7583 - loss: 0.5405\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7606 - loss: 0.5391\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7607 - loss: 0.5391\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.7602 - loss: 0.5388\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7552 - loss: 0.5451\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7604 - loss: 0.5395\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7587 - loss: 0.5418\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7619 - loss: 0.5372\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7570 - loss: 0.5424\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.7605 - loss: 0.5385\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7599 - loss: 0.5387\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7584 - loss: 0.5400\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7572 - loss: 0.5428\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7595 - loss: 0.5399\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - accuracy: 0.7607 - loss: 0.5392\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7567 - loss: 0.5431\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7620 - loss: 0.5366\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7597 - loss: 0.5394\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7647 - loss: 0.5336\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.7584 - loss: 0.5418\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7588 - loss: 0.5406\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7591 - loss: 0.5394\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7581 - loss: 0.5416\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - accuracy: 0.7588 - loss: 0.5402\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7590 - loss: 0.5397\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.7595 - loss: 0.5405\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7613 - loss: 0.5382\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.7640 - loss: 0.5333\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7613 - loss: 0.5376\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7473 - loss: 0.5749\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7617 - loss: 0.5468\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7606 - loss: 0.5440\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - accuracy: 0.7636 - loss: 0.5399\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7610 - loss: 0.5428\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7641 - loss: 0.5389\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - accuracy: 0.7592 - loss: 0.5439\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7610 - loss: 0.5421\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - accuracy: 0.7600 - loss: 0.5416\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7560 - loss: 0.5468\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.7654 - loss: 0.5353\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7595 - loss: 0.5417\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.7560 - loss: 0.5462\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7631 - loss: 0.5380\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7612 - loss: 0.5387\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7622 - loss: 0.5377\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7589 - loss: 0.5420\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7571 - loss: 0.5441\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7559 - loss: 0.5442\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7590 - loss: 0.5420\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472us/step - accuracy: 0.7592 - loss: 0.5414\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.7584 - loss: 0.5429\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7602 - loss: 0.5400\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.7591 - loss: 0.5406\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7615 - loss: 0.5382\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - accuracy: 0.7587 - loss: 0.5415\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7608 - loss: 0.5390\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7634 - loss: 0.5364\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7587 - loss: 0.5404\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.7562 - loss: 0.5430\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7582 - loss: 0.5419\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7615 - loss: 0.5387\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.7593 - loss: 0.5403\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.7573 - loss: 0.5425\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - accuracy: 0.7566 - loss: 0.5433\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7604 - loss: 0.5396\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.7600 - loss: 0.5393\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7601 - loss: 0.5385\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7609 - loss: 0.5394\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7599 - loss: 0.5393\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.7605 - loss: 0.5386\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7578 - loss: 0.5422\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7591 - loss: 0.5403\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.7607 - loss: 0.5389\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7599 - loss: 0.5396\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7596 - loss: 0.5402\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7622 - loss: 0.5369\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step - accuracy: 0.7588 - loss: 0.5409\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - accuracy: 0.7612 - loss: 0.5388\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - accuracy: 0.7625 - loss: 0.5377\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7601 - loss: 0.5402\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472us/step - accuracy: 0.7553 - loss: 0.5445\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7602 - loss: 0.5391\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7626 - loss: 0.5361\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - accuracy: 0.7581 - loss: 0.5409\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - accuracy: 0.7580 - loss: 0.5413\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7665 - loss: 0.5314\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7561 - loss: 0.5436\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7606 - loss: 0.5378\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7622 - loss: 0.5373\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - accuracy: 0.7586 - loss: 0.5408\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7627 - loss: 0.5358\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - accuracy: 0.7590 - loss: 0.5397\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7613 - loss: 0.5376\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.7592 - loss: 0.5398\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482us/step - accuracy: 0.7564 - loss: 0.5426\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - accuracy: 0.7585 - loss: 0.5415\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - accuracy: 0.7666 - loss: 0.5315\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - accuracy: 0.7627 - loss: 0.5360\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482us/step - accuracy: 0.7602 - loss: 0.5382\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457us/step - accuracy: 0.7619 - loss: 0.5378\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.7643 - loss: 0.5336\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7601 - loss: 0.5394\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7603 - loss: 0.5395\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7625 - loss: 0.5371\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7625 - loss: 0.5368\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - accuracy: 0.7647 - loss: 0.5333\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7614 - loss: 0.5370\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7591 - loss: 0.5398\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492us/step - accuracy: 0.7637 - loss: 0.5350\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7595 - loss: 0.5390\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7602 - loss: 0.5385\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - accuracy: 0.7629 - loss: 0.5359\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step - accuracy: 0.7606 - loss: 0.5393\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7628 - loss: 0.5361\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7597 - loss: 0.5390\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - accuracy: 0.7593 - loss: 0.5402\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - accuracy: 0.7594 - loss: 0.5399\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7609 - loss: 0.5375\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7615 - loss: 0.5377\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - accuracy: 0.7565 - loss: 0.5431\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - accuracy: 0.7582 - loss: 0.5406\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - accuracy: 0.7601 - loss: 0.5392\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - accuracy: 0.7586 - loss: 0.5400\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7612 - loss: 0.5374\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step - accuracy: 0.7618 - loss: 0.5366\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7615 - loss: 0.5379\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7595 - loss: 0.5389\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7616 - loss: 0.5377\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7623 - loss: 0.5367\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.5841 - loss: 0.7176\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.7563 - loss: 0.5538\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7626 - loss: 0.5421\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451us/step - accuracy: 0.7600 - loss: 0.5451\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step - accuracy: 0.7617 - loss: 0.5419\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7616 - loss: 0.5428\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466us/step - accuracy: 0.7613 - loss: 0.5425\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7603 - loss: 0.5440\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - accuracy: 0.7604 - loss: 0.5434\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step - accuracy: 0.7574 - loss: 0.5462\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7590 - loss: 0.5429\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7588 - loss: 0.5423\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - accuracy: 0.7599 - loss: 0.5406\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.7583 - loss: 0.5420\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7579 - loss: 0.5429\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - accuracy: 0.7608 - loss: 0.5402\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7591 - loss: 0.5407\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.7620 - loss: 0.5371\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7600 - loss: 0.5403\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step - accuracy: 0.7600 - loss: 0.5401\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step - accuracy: 0.7607 - loss: 0.5394\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7561 - loss: 0.5441\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7625 - loss: 0.5369\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7604 - loss: 0.5394\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7583 - loss: 0.5412\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7574 - loss: 0.5428\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7612 - loss: 0.5378\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - accuracy: 0.7631 - loss: 0.5368\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - accuracy: 0.7618 - loss: 0.5363\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7575 - loss: 0.5421\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7605 - loss: 0.5383\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - accuracy: 0.7633 - loss: 0.5355\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.7604 - loss: 0.5400\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.7601 - loss: 0.5388\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7593 - loss: 0.5401\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.7580 - loss: 0.5420\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7592 - loss: 0.5397\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step - accuracy: 0.7624 - loss: 0.5363\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7576 - loss: 0.5422\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 451us/step - accuracy: 0.7592 - loss: 0.5408\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - accuracy: 0.7609 - loss: 0.5383\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7569 - loss: 0.5438\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.7624 - loss: 0.5370\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.7622 - loss: 0.5369\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7621 - loss: 0.5377\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - accuracy: 0.7601 - loss: 0.5400\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441us/step - accuracy: 0.7584 - loss: 0.5414\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7589 - loss: 0.5415\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7615 - loss: 0.5380\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7588 - loss: 0.5406\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - accuracy: 0.7624 - loss: 0.5358\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7593 - loss: 0.5406\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7597 - loss: 0.5403\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7640 - loss: 0.5350\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7633 - loss: 0.5345\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7644 - loss: 0.5336\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7609 - loss: 0.5386\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.7609 - loss: 0.5374\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7562 - loss: 0.5432\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7561 - loss: 0.5428\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7596 - loss: 0.5381\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.7599 - loss: 0.5390\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.7615 - loss: 0.5370\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.7618 - loss: 0.5357\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7615 - loss: 0.5362\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.7617 - loss: 0.5359\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7569 - loss: 0.5421\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7621 - loss: 0.5370\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.7595 - loss: 0.5384\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7586 - loss: 0.5395\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7624 - loss: 0.5344\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7572 - loss: 0.5409\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7587 - loss: 0.5387\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7585 - loss: 0.5400\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.7624 - loss: 0.5345\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.7612 - loss: 0.5358\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7602 - loss: 0.5367\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.7601 - loss: 0.5381\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.7594 - loss: 0.5379\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.7598 - loss: 0.5373\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7620 - loss: 0.5358\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7629 - loss: 0.5344\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - accuracy: 0.7581 - loss: 0.5387\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7620 - loss: 0.5348\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7564 - loss: 0.5420\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7606 - loss: 0.5367\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7609 - loss: 0.5368\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.7581 - loss: 0.5407\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.7569 - loss: 0.5416\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7598 - loss: 0.5372\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7592 - loss: 0.5376\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7613 - loss: 0.5354\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7579 - loss: 0.5393\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7609 - loss: 0.5365\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7601 - loss: 0.5370\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7595 - loss: 0.5381\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7594 - loss: 0.5376\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7627 - loss: 0.5346\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7620 - loss: 0.5351\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7561 - loss: 0.5418\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.7050 - loss: 0.6021\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7619 - loss: 0.5459\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.7608 - loss: 0.5436\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7616 - loss: 0.5428\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.7595 - loss: 0.5443\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.7619 - loss: 0.5407\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.7589 - loss: 0.5447\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.7614 - loss: 0.5427\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7583 - loss: 0.5446\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.7633 - loss: 0.5397\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.7589 - loss: 0.5431\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.7622 - loss: 0.5392\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7611 - loss: 0.5412\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7571 - loss: 0.5446\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.7584 - loss: 0.5455\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7585 - loss: 0.5437\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7629 - loss: 0.5373\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.7595 - loss: 0.5430\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7526 - loss: 0.5503\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7583 - loss: 0.5440\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7595 - loss: 0.5428\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7626 - loss: 0.5390\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.7575 - loss: 0.5435\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.7606 - loss: 0.5407\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.7615 - loss: 0.5398\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7603 - loss: 0.5406\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - accuracy: 0.7599 - loss: 0.5425\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7547 - loss: 0.5490\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7586 - loss: 0.5431\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.7612 - loss: 0.5412\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.7592 - loss: 0.5422\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.7635 - loss: 0.5381\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7624 - loss: 0.5404\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.7584 - loss: 0.5449\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.7539 - loss: 0.5480\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7609 - loss: 0.5413\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.7586 - loss: 0.5431\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.7617 - loss: 0.5390\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7587 - loss: 0.5430\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7601 - loss: 0.5414\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.7589 - loss: 0.5438\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.7581 - loss: 0.5443\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.7608 - loss: 0.5402\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7617 - loss: 0.5396\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7618 - loss: 0.5392\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585us/step - accuracy: 0.7612 - loss: 0.5389\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.7588 - loss: 0.5417\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7634 - loss: 0.5383\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.7592 - loss: 0.5418\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7610 - loss: 0.5393\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7622 - loss: 0.5385\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7598 - loss: 0.5410\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.7593 - loss: 0.5413\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7605 - loss: 0.5407\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7627 - loss: 0.5376\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7588 - loss: 0.5432\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7597 - loss: 0.5407\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7581 - loss: 0.5427\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7620 - loss: 0.5382\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7575 - loss: 0.5422\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7602 - loss: 0.5389\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7599 - loss: 0.5399\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7636 - loss: 0.5357\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - accuracy: 0.7613 - loss: 0.5395\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7591 - loss: 0.5410\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7588 - loss: 0.5419\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7611 - loss: 0.5384\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7622 - loss: 0.5365\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7611 - loss: 0.5376\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - accuracy: 0.7595 - loss: 0.5400\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7640 - loss: 0.5341\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.7554 - loss: 0.5441\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7602 - loss: 0.5377\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7599 - loss: 0.5389\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7589 - loss: 0.5411\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7608 - loss: 0.5374\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7549 - loss: 0.5452\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442us/step - accuracy: 0.7595 - loss: 0.5392\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7581 - loss: 0.5408\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step - accuracy: 0.7600 - loss: 0.5395\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.7584 - loss: 0.5401\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - accuracy: 0.7615 - loss: 0.5383\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7601 - loss: 0.5388\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432us/step - accuracy: 0.7610 - loss: 0.5381\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step - accuracy: 0.7571 - loss: 0.5424\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - accuracy: 0.7623 - loss: 0.5374\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7622 - loss: 0.5367\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432us/step - accuracy: 0.7586 - loss: 0.5414\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - accuracy: 0.7583 - loss: 0.5411\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 475us/step - accuracy: 0.7606 - loss: 0.5377\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448us/step - accuracy: 0.7632 - loss: 0.5352\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7615 - loss: 0.5385\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7629 - loss: 0.5363\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7620 - loss: 0.5364\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7614 - loss: 0.5381\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.7601 - loss: 0.5399\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7613 - loss: 0.5379\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.7582 - loss: 0.5402\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.7649 - loss: 0.5339\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7624 - loss: 0.5358\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - accuracy: 0.7289 - loss: 0.5796\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.7586 - loss: 0.5462\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.7597 - loss: 0.5427\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7575 - loss: 0.5452\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.7594 - loss: 0.5426\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.7599 - loss: 0.5414\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.7608 - loss: 0.5407\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7604 - loss: 0.5392\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7576 - loss: 0.5437\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7588 - loss: 0.5422\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.7628 - loss: 0.5373\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7605 - loss: 0.5406\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7596 - loss: 0.5403\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.7606 - loss: 0.5395\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7606 - loss: 0.5391\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7614 - loss: 0.5381\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7613 - loss: 0.5394\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7585 - loss: 0.5428\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7591 - loss: 0.5418\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7593 - loss: 0.5412\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7602 - loss: 0.5400\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7586 - loss: 0.5416\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.7644 - loss: 0.5347\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502us/step - accuracy: 0.7592 - loss: 0.5411\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7621 - loss: 0.5376\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step - accuracy: 0.7579 - loss: 0.5423\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7593 - loss: 0.5412\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7647 - loss: 0.5359\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.7569 - loss: 0.5448\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7600 - loss: 0.5397\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7604 - loss: 0.5399\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7591 - loss: 0.5411\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7615 - loss: 0.5390\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7590 - loss: 0.5413\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7608 - loss: 0.5401\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7575 - loss: 0.5421\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7618 - loss: 0.5383\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - accuracy: 0.7603 - loss: 0.5394\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.7600 - loss: 0.5404\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7620 - loss: 0.5382\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - accuracy: 0.7610 - loss: 0.5396\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - accuracy: 0.7626 - loss: 0.5385\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7600 - loss: 0.5398\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7612 - loss: 0.5386\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step - accuracy: 0.7593 - loss: 0.5402\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7630 - loss: 0.5376\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7595 - loss: 0.5405\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7600 - loss: 0.5404\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7608 - loss: 0.5388\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7613 - loss: 0.5393\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.7631 - loss: 0.5366\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.7583 - loss: 0.5419\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7594 - loss: 0.5399\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7569 - loss: 0.5440\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - accuracy: 0.7621 - loss: 0.5374\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - accuracy: 0.7600 - loss: 0.5405\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7582 - loss: 0.5413\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7609 - loss: 0.5391\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7587 - loss: 0.5421\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7607 - loss: 0.5398\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7595 - loss: 0.5408\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7586 - loss: 0.5423\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7601 - loss: 0.5400\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7592 - loss: 0.5409\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7613 - loss: 0.5384\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.7606 - loss: 0.5382\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7599 - loss: 0.5402\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7563 - loss: 0.5448\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7622 - loss: 0.5366\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7616 - loss: 0.5384\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 486us/step - accuracy: 0.7599 - loss: 0.5402\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7599 - loss: 0.5402\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7598 - loss: 0.5399\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7612 - loss: 0.5382\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 484us/step - accuracy: 0.7630 - loss: 0.5376\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7614 - loss: 0.5386\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - accuracy: 0.7596 - loss: 0.5396\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7597 - loss: 0.5407\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7574 - loss: 0.5427\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.7595 - loss: 0.5412\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7604 - loss: 0.5393\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7578 - loss: 0.5425\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7640 - loss: 0.5353\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.7585 - loss: 0.5411\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.7595 - loss: 0.5395\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7593 - loss: 0.5410\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7607 - loss: 0.5395\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7599 - loss: 0.5399\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7634 - loss: 0.5363\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 0.7611 - loss: 0.5394\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.7591 - loss: 0.5405\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.7606 - loss: 0.5396\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.7599 - loss: 0.5403\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7609 - loss: 0.5393\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.7613 - loss: 0.5391\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7594 - loss: 0.5406\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7574 - loss: 0.5436\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7625 - loss: 0.5363\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7614 - loss: 0.5372\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7584 - loss: 0.5420\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.6564 - loss: 0.6443\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7633 - loss: 0.5445\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.7651 - loss: 0.5396\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7579 - loss: 0.5469\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.7604 - loss: 0.5440\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.7609 - loss: 0.5440\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - accuracy: 0.7642 - loss: 0.5399\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.7578 - loss: 0.5478\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7597 - loss: 0.5442\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.7591 - loss: 0.5444\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7571 - loss: 0.5473\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7574 - loss: 0.5467\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7612 - loss: 0.5418\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.7602 - loss: 0.5427\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7599 - loss: 0.5440\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7566 - loss: 0.5464\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.7602 - loss: 0.5422\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.7603 - loss: 0.5435\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.7592 - loss: 0.5434\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7575 - loss: 0.5455\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7606 - loss: 0.5426\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7587 - loss: 0.5443\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7585 - loss: 0.5450\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7584 - loss: 0.5443\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.7590 - loss: 0.5439\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.7571 - loss: 0.5452\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7600 - loss: 0.5424\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.7589 - loss: 0.5429\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7591 - loss: 0.5429\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.7591 - loss: 0.5417\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7620 - loss: 0.5384\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7606 - loss: 0.5397\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step - accuracy: 0.7619 - loss: 0.5377\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7578 - loss: 0.5423\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7599 - loss: 0.5386\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7613 - loss: 0.5384\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7600 - loss: 0.5385\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7610 - loss: 0.5391\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7589 - loss: 0.5406\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7622 - loss: 0.5366\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.7611 - loss: 0.5378\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7612 - loss: 0.5371\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7626 - loss: 0.5365\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7601 - loss: 0.5390\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7617 - loss: 0.5368\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.7653 - loss: 0.5334\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7620 - loss: 0.5375\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7606 - loss: 0.5390\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.7605 - loss: 0.5382\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7607 - loss: 0.5382\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.7594 - loss: 0.5403\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7552 - loss: 0.5453\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.7579 - loss: 0.5421\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.7620 - loss: 0.5356\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7604 - loss: 0.5385\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7597 - loss: 0.5401\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.7616 - loss: 0.5368\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7577 - loss: 0.5416\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7566 - loss: 0.5434\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7580 - loss: 0.5420\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7585 - loss: 0.5396\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7622 - loss: 0.5369\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.7592 - loss: 0.5408\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585us/step - accuracy: 0.7617 - loss: 0.5382\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7581 - loss: 0.5410\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7592 - loss: 0.5402\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7596 - loss: 0.5407\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482us/step - accuracy: 0.7584 - loss: 0.5400\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7586 - loss: 0.5404\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7629 - loss: 0.5365\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7628 - loss: 0.5351\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7632 - loss: 0.5357\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7617 - loss: 0.5367\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - accuracy: 0.7614 - loss: 0.5373\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.7615 - loss: 0.5373\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.7611 - loss: 0.5383\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - accuracy: 0.7602 - loss: 0.5386\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - accuracy: 0.7570 - loss: 0.5429\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7646 - loss: 0.5332\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7604 - loss: 0.5389\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7583 - loss: 0.5413\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7598 - loss: 0.5400\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.7576 - loss: 0.5426\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - accuracy: 0.7611 - loss: 0.5372\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7591 - loss: 0.5391\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7590 - loss: 0.5399\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478us/step - accuracy: 0.7614 - loss: 0.5370\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.7607 - loss: 0.5385\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7610 - loss: 0.5383\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7585 - loss: 0.5415\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - accuracy: 0.7600 - loss: 0.5399\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7616 - loss: 0.5369\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7586 - loss: 0.5405\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7573 - loss: 0.5426\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7604 - loss: 0.5374\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7625 - loss: 0.5366\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7607 - loss: 0.5383\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7570 - loss: 0.5422\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7617 - loss: 0.5374\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7613 - loss: 0.5377\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - accuracy: 0.7319 - loss: 0.5831\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7565 - loss: 0.5494\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7583 - loss: 0.5450\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7582 - loss: 0.5461\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7605 - loss: 0.5416\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7614 - loss: 0.5404\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7596 - loss: 0.5409\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7624 - loss: 0.5390\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7601 - loss: 0.5395\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7591 - loss: 0.5409\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7616 - loss: 0.5375\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step - accuracy: 0.7620 - loss: 0.5392\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7612 - loss: 0.5382\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7619 - loss: 0.5369\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7618 - loss: 0.5373\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.7598 - loss: 0.5411\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7610 - loss: 0.5389\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7605 - loss: 0.5385\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7568 - loss: 0.5421\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7609 - loss: 0.5386\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7573 - loss: 0.5415\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.7603 - loss: 0.5394\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7598 - loss: 0.5397\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7629 - loss: 0.5362\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7597 - loss: 0.5390\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7594 - loss: 0.5395\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7584 - loss: 0.5411\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7607 - loss: 0.5391\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.7599 - loss: 0.5405\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7620 - loss: 0.5366\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.7590 - loss: 0.5399\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7573 - loss: 0.5424\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7609 - loss: 0.5377\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7592 - loss: 0.5408\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.7573 - loss: 0.5417\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.7615 - loss: 0.5370\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7603 - loss: 0.5387\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7609 - loss: 0.5378\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step - accuracy: 0.7609 - loss: 0.5376\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7576 - loss: 0.5418\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.7570 - loss: 0.5428\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - accuracy: 0.7608 - loss: 0.5378\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step - accuracy: 0.7593 - loss: 0.5406\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.7621 - loss: 0.5376\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7617 - loss: 0.5368\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7589 - loss: 0.5403\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7627 - loss: 0.5361\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step - accuracy: 0.7589 - loss: 0.5405\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7624 - loss: 0.5352\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7567 - loss: 0.5429\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.7614 - loss: 0.5375\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7617 - loss: 0.5361\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7599 - loss: 0.5380\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7599 - loss: 0.5394\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7612 - loss: 0.5383\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - accuracy: 0.7607 - loss: 0.5387\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.7586 - loss: 0.5408\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.7626 - loss: 0.5355\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7602 - loss: 0.5398\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.7606 - loss: 0.5387\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7578 - loss: 0.5410\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7593 - loss: 0.5402\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7580 - loss: 0.5409\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7550 - loss: 0.5446\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.7594 - loss: 0.5392\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7581 - loss: 0.5399\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7592 - loss: 0.5394\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7639 - loss: 0.5347\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7594 - loss: 0.5388\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7565 - loss: 0.5429\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7637 - loss: 0.5356\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607us/step - accuracy: 0.7619 - loss: 0.5364\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7623 - loss: 0.5369\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.7584 - loss: 0.5407\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7626 - loss: 0.5357\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.7607 - loss: 0.5388\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.7596 - loss: 0.5396\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.7603 - loss: 0.5376\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7608 - loss: 0.5393\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7628 - loss: 0.5368\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.7618 - loss: 0.5377\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 767us/step - accuracy: 0.7582 - loss: 0.5414\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.7611 - loss: 0.5363\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - accuracy: 0.7592 - loss: 0.5401\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.7596 - loss: 0.5387\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7610 - loss: 0.5371\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.7594 - loss: 0.5396\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7625 - loss: 0.5354\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.7587 - loss: 0.5399\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584us/step - accuracy: 0.7591 - loss: 0.5404\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7569 - loss: 0.5420\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7592 - loss: 0.5383\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7626 - loss: 0.5370\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.7579 - loss: 0.5408\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7572 - loss: 0.5412\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.7644 - loss: 0.5345\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7557 - loss: 0.5434\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.7593 - loss: 0.5397\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7645 - loss: 0.5342\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.7574 - loss: 0.5419\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.5758 - loss: 0.7614\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7600 - loss: 0.5519\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7593 - loss: 0.5470\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - accuracy: 0.7595 - loss: 0.5453\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - accuracy: 0.7596 - loss: 0.5454\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7585 - loss: 0.5457\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - accuracy: 0.7618 - loss: 0.5429\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7627 - loss: 0.5411\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7590 - loss: 0.5438\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.7590 - loss: 0.5444\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.7613 - loss: 0.5422\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7614 - loss: 0.5414\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7642 - loss: 0.5385\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7570 - loss: 0.5469\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.7605 - loss: 0.5431\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7584 - loss: 0.5448\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465us/step - accuracy: 0.7548 - loss: 0.5494\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - accuracy: 0.7599 - loss: 0.5428\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478us/step - accuracy: 0.7579 - loss: 0.5447\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.7600 - loss: 0.5427\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.7622 - loss: 0.5402\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.7607 - loss: 0.5407\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7614 - loss: 0.5404\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - accuracy: 0.7582 - loss: 0.5439\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.7629 - loss: 0.5387\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7603 - loss: 0.5420\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.7610 - loss: 0.5403\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - accuracy: 0.7622 - loss: 0.5383\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7617 - loss: 0.5402\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7566 - loss: 0.5449\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7632 - loss: 0.5377\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7594 - loss: 0.5411\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7601 - loss: 0.5408\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7602 - loss: 0.5401\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - accuracy: 0.7583 - loss: 0.5420\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7616 - loss: 0.5390\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471us/step - accuracy: 0.7621 - loss: 0.5377\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.7612 - loss: 0.5400\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7635 - loss: 0.5365\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485us/step - accuracy: 0.7610 - loss: 0.5388\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7618 - loss: 0.5372\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7608 - loss: 0.5386\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7617 - loss: 0.5383\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7597 - loss: 0.5409\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.7602 - loss: 0.5404\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7597 - loss: 0.5396\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7595 - loss: 0.5409\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7622 - loss: 0.5372\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7617 - loss: 0.5357\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7580 - loss: 0.5406\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7575 - loss: 0.5419\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7624 - loss: 0.5369\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.7574 - loss: 0.5412\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7589 - loss: 0.5407\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7580 - loss: 0.5419\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.7598 - loss: 0.5383\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7587 - loss: 0.5396\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7619 - loss: 0.5378\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.7577 - loss: 0.5423\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7609 - loss: 0.5382\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.7599 - loss: 0.5386\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7587 - loss: 0.5401\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7592 - loss: 0.5401\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7572 - loss: 0.5429\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7582 - loss: 0.5407\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7615 - loss: 0.5383\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.7603 - loss: 0.5383\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - accuracy: 0.7610 - loss: 0.5387\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - accuracy: 0.7598 - loss: 0.5394\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7626 - loss: 0.5349\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7610 - loss: 0.5375\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471us/step - accuracy: 0.7595 - loss: 0.5382\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7574 - loss: 0.5425\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - accuracy: 0.7614 - loss: 0.5358\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7598 - loss: 0.5395\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.7604 - loss: 0.5382\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7596 - loss: 0.5384\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7592 - loss: 0.5400\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - accuracy: 0.7616 - loss: 0.5372\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7606 - loss: 0.5381\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7651 - loss: 0.5322\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.7595 - loss: 0.5408\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.7629 - loss: 0.5352\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.7599 - loss: 0.5384\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7613 - loss: 0.5357\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7618 - loss: 0.5366\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7596 - loss: 0.5393\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.7639 - loss: 0.5342\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7618 - loss: 0.5361\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.7569 - loss: 0.5423\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 498us/step - accuracy: 0.7575 - loss: 0.5408\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7618 - loss: 0.5363\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7604 - loss: 0.5368\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7594 - loss: 0.5384\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - accuracy: 0.7607 - loss: 0.5369\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7596 - loss: 0.5380\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7612 - loss: 0.5359\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7613 - loss: 0.5362\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7594 - loss: 0.5394\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7569 - loss: 0.5411\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455us/step - accuracy: 0.7477 - loss: 0.5771\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.7625 - loss: 0.5423\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7603 - loss: 0.5440\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7625 - loss: 0.5405\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7585 - loss: 0.5444\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7586 - loss: 0.5442\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.7566 - loss: 0.5460\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7568 - loss: 0.5460\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7622 - loss: 0.5400\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7611 - loss: 0.5397\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.7615 - loss: 0.5397\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.7564 - loss: 0.5461\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.7622 - loss: 0.5385\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.7610 - loss: 0.5390\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.7569 - loss: 0.5439\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610us/step - accuracy: 0.7593 - loss: 0.5410\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7574 - loss: 0.5429\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.7570 - loss: 0.5436\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.7625 - loss: 0.5373\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.7596 - loss: 0.5398\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.7628 - loss: 0.5367\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7581 - loss: 0.5419\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 489us/step - accuracy: 0.7588 - loss: 0.5411\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.7592 - loss: 0.5390\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7571 - loss: 0.5425\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.7639 - loss: 0.5353\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.7618 - loss: 0.5376\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.7596 - loss: 0.5411\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7609 - loss: 0.5381\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7605 - loss: 0.5385\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7608 - loss: 0.5384\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7621 - loss: 0.5362\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7566 - loss: 0.5429\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.7602 - loss: 0.5391\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.7621 - loss: 0.5375\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.7605 - loss: 0.5376\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7642 - loss: 0.5346\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7612 - loss: 0.5386\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.7586 - loss: 0.5406\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.7584 - loss: 0.5411\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.7592 - loss: 0.5399\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7628 - loss: 0.5361\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7592 - loss: 0.5396\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.7586 - loss: 0.5397\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.7608 - loss: 0.5391\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7618 - loss: 0.5368\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7616 - loss: 0.5366\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.7607 - loss: 0.5378\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7562 - loss: 0.5431\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.7636 - loss: 0.5342\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.7611 - loss: 0.5372\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7636 - loss: 0.5350\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.7624 - loss: 0.5368\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.7591 - loss: 0.5406\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7615 - loss: 0.5370\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.7638 - loss: 0.5349\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.7610 - loss: 0.5385\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.7631 - loss: 0.5355\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.7628 - loss: 0.5363\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7586 - loss: 0.5402\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7582 - loss: 0.5401\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7608 - loss: 0.5376\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.7606 - loss: 0.5379\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.7588 - loss: 0.5395\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7580 - loss: 0.5413\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - accuracy: 0.7598 - loss: 0.5388\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.7590 - loss: 0.5403\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.7643 - loss: 0.5342\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7591 - loss: 0.5396\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.7589 - loss: 0.5398\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.7574 - loss: 0.5425\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.7588 - loss: 0.5387\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.7631 - loss: 0.5339\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 480us/step - accuracy: 0.7619 - loss: 0.5367\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.7624 - loss: 0.5366\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.7630 - loss: 0.5359\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.7616 - loss: 0.5381\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7631 - loss: 0.5352\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.7582 - loss: 0.5398\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7600 - loss: 0.5395\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467us/step - accuracy: 0.7615 - loss: 0.5371\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7605 - loss: 0.5385\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7592 - loss: 0.5389\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7618 - loss: 0.5374\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.7611 - loss: 0.5381\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7592 - loss: 0.5393\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7592 - loss: 0.5396\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.7606 - loss: 0.5387\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.7557 - loss: 0.5431\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7630 - loss: 0.5352\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.7615 - loss: 0.5375\n",
      "Epoch 92/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.7594 - loss: 0.5397\n",
      "Epoch 93/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - accuracy: 0.7621 - loss: 0.5358\n",
      "Epoch 94/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.7628 - loss: 0.5356\n",
      "Epoch 95/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7625 - loss: 0.5351\n",
      "Epoch 96/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7574 - loss: 0.5416\n",
      "Epoch 97/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7580 - loss: 0.5405\n",
      "Epoch 98/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7605 - loss: 0.5375\n",
      "Epoch 99/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.7559 - loss: 0.5427\n",
      "Epoch 100/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.7603 - loss: 0.5382\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step\n",
      "Epoch 1/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 626us/step - accuracy: 0.7463 - loss: 0.5796\n",
      "Epoch 2/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.7623 - loss: 0.5445\n",
      "Epoch 3/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7613 - loss: 0.5441\n",
      "Epoch 4/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7588 - loss: 0.5444\n",
      "Epoch 5/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7587 - loss: 0.5441\n",
      "Epoch 6/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7577 - loss: 0.5453\n",
      "Epoch 7/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.7609 - loss: 0.5411\n",
      "Epoch 8/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - accuracy: 0.7583 - loss: 0.5435\n",
      "Epoch 9/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7589 - loss: 0.5431\n",
      "Epoch 10/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.7615 - loss: 0.5415\n",
      "Epoch 11/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7585 - loss: 0.5429\n",
      "Epoch 12/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.7628 - loss: 0.5391\n",
      "Epoch 13/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.7620 - loss: 0.5398\n",
      "Epoch 14/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.7620 - loss: 0.5398\n",
      "Epoch 15/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.7569 - loss: 0.5452\n",
      "Epoch 16/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.7597 - loss: 0.5422\n",
      "Epoch 17/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.7592 - loss: 0.5424\n",
      "Epoch 18/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.7610 - loss: 0.5410\n",
      "Epoch 19/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.7640 - loss: 0.5364\n",
      "Epoch 20/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7587 - loss: 0.5431\n",
      "Epoch 21/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7591 - loss: 0.5433\n",
      "Epoch 22/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.7600 - loss: 0.5417\n",
      "Epoch 23/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.7590 - loss: 0.5414\n",
      "Epoch 24/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7606 - loss: 0.5404\n",
      "Epoch 25/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.7598 - loss: 0.5398\n",
      "Epoch 26/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.7580 - loss: 0.5439\n",
      "Epoch 27/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.7608 - loss: 0.5404\n",
      "Epoch 28/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.7589 - loss: 0.5419\n",
      "Epoch 29/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7599 - loss: 0.5416\n",
      "Epoch 30/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - accuracy: 0.7618 - loss: 0.5375\n",
      "Epoch 31/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7620 - loss: 0.5396\n",
      "Epoch 32/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.7607 - loss: 0.5399\n",
      "Epoch 33/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.7586 - loss: 0.5423\n",
      "Epoch 34/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7595 - loss: 0.5410\n",
      "Epoch 35/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7588 - loss: 0.5424\n",
      "Epoch 36/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7585 - loss: 0.5428\n",
      "Epoch 37/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7597 - loss: 0.5409\n",
      "Epoch 38/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.7618 - loss: 0.5396\n",
      "Epoch 39/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7595 - loss: 0.5417\n",
      "Epoch 40/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500us/step - accuracy: 0.7606 - loss: 0.5388\n",
      "Epoch 41/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7590 - loss: 0.5426\n",
      "Epoch 42/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.7555 - loss: 0.5454\n",
      "Epoch 43/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7565 - loss: 0.5446\n",
      "Epoch 44/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501us/step - accuracy: 0.7597 - loss: 0.5419\n",
      "Epoch 45/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7605 - loss: 0.5394\n",
      "Epoch 46/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.7591 - loss: 0.5408\n",
      "Epoch 47/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7587 - loss: 0.5390\n",
      "Epoch 48/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.7587 - loss: 0.5417\n",
      "Epoch 49/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.7579 - loss: 0.5417\n",
      "Epoch 50/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.7588 - loss: 0.5419\n",
      "Epoch 51/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.7613 - loss: 0.5379\n",
      "Epoch 52/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7601 - loss: 0.5397\n",
      "Epoch 53/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.7567 - loss: 0.5422\n",
      "Epoch 54/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.7593 - loss: 0.5402\n",
      "Epoch 55/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7608 - loss: 0.5384\n",
      "Epoch 56/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7617 - loss: 0.5381\n",
      "Epoch 57/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.7580 - loss: 0.5421\n",
      "Epoch 58/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7614 - loss: 0.5373\n",
      "Epoch 59/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.7605 - loss: 0.5388\n",
      "Epoch 60/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 0.7590 - loss: 0.5397\n",
      "Epoch 61/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.7599 - loss: 0.5397\n",
      "Epoch 62/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.7606 - loss: 0.5386\n",
      "Epoch 63/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.7556 - loss: 0.5451\n",
      "Epoch 64/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7599 - loss: 0.5407\n",
      "Epoch 65/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7617 - loss: 0.5373\n",
      "Epoch 66/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.7596 - loss: 0.5393\n",
      "Epoch 67/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.7627 - loss: 0.5369\n",
      "Epoch 68/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7583 - loss: 0.5419\n",
      "Epoch 69/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.7588 - loss: 0.5406\n",
      "Epoch 70/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.7589 - loss: 0.5415\n",
      "Epoch 71/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.7584 - loss: 0.5413\n",
      "Epoch 72/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7618 - loss: 0.5380\n",
      "Epoch 73/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.7585 - loss: 0.5411\n",
      "Epoch 74/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.7603 - loss: 0.5392\n",
      "Epoch 75/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 499us/step - accuracy: 0.7659 - loss: 0.5322\n",
      "Epoch 76/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7566 - loss: 0.5429\n",
      "Epoch 77/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.7593 - loss: 0.5400\n",
      "Epoch 78/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7583 - loss: 0.5403\n",
      "Epoch 79/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7595 - loss: 0.5397\n",
      "Epoch 80/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.7599 - loss: 0.5402\n",
      "Epoch 81/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.7581 - loss: 0.5423\n",
      "Epoch 82/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7570 - loss: 0.5419\n",
      "Epoch 83/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.7601 - loss: 0.5401\n",
      "Epoch 84/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.7615 - loss: 0.5376\n",
      "Epoch 85/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7618 - loss: 0.5373\n",
      "Epoch 86/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.7591 - loss: 0.5412\n",
      "Epoch 87/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.7588 - loss: 0.5403\n",
      "Epoch 88/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7605 - loss: 0.5384\n",
      "Epoch 89/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.7600 - loss: 0.5400\n",
      "Epoch 90/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.7624 - loss: 0.5365\n",
      "Epoch 91/100\n",
      "\u001b[1m1432/1432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.7595 - loss: 0.5395\n",
      "Epoch 92/100\n",
      "\u001b[1m 620/1432\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7617 - loss: 0.5385"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[278], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracies\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy Standard Deviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracies\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[0;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m    767\u001b[0m )\n\u001b[0;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\scikeras\\wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_standard, y=y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy Mean: {accuracies.mean()}, Accuracy Standard Deviation: {accuracies.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.2 Using **F1-Score** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = cross_val_score(estimator=classifier, X=X_standard, y=y, cv=kfold, scoring='f1')\n",
    "\n",
    "print(f\"F1-Score Mean: {f1_scores.mean()}, F1-Score Standard Deviation: {f1_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.3 Using **Precision** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = cross_val_score(estimator=classifier, X=X_standard, y=y, cv=kfold, scoring='precision')\n",
    "\n",
    "print(f\"Precision Mean: {precisions.mean()}, Precision Standard Deviation: {precisions.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.4 Using **Recall** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = cross_val_score(estimator=classifier, X=X_standard, y=y, cv=kfold, scoring='recall')\n",
    "\n",
    "print(f\"Recall Mean: {recalls.mean()}, Recall Standard Deviation: {recalls.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.5 Using ROC-AUC as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs = cross_val_score(estimator=classifier, X=X_standard, y=y, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "print(f\"ROC-AUC Mean: {roc_aucs.mean()}, ROC-AUC Standard Deviation: {roc_aucs.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 6. PERFORM HOLD-OUT VALIDATION TO ASSESS THE ARTIFICIAL NEURAL NETWORK MODEL'S PERFORMANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, classification_report\n",
    "\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. For Classification Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. For Classification Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_error = 1 - accuracy\n",
    "\n",
    "print(f\"Classification Error: {classification_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. For the Sensitivity, Recall Score, Probability of Detection, True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Sensitivity / Recall / True Positive Rate: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. For the Specificity or True Negative Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = TN / float(TN + FP)\n",
    "\n",
    "print(f\"Specificity / True Negative Rate: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. For the False Positive Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. For the Precision or Positive Predictive Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision / Positive Predictive Value: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. For the F1-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. For the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already printed in Part 4, included here for completeness\n",
    "print(\"Classification Report:\")\n",
    "\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. For the Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_vals, recall_vals, threshold = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(recall_vals, precision_vals, marker='.')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.title('Precision-Recall Curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J. For the ROC Curve with AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.1 For the Receiver Operating Curve (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.2 For the Area Under the Curve (AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.3 To Plot the ROC Curve with AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.4 For the Plot of Baseline for AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Baseline')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve with Baseline')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 7. PERFORM HYPERPARAMETER TUNING TO OPTIMIZE THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Tune First the Batch Size and Epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(batch_size=32, epochs=100):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(X_train_sm.shape[1],)))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.2 To Import gridSearchCV Class and Optimize the Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'batch_size': [25, 32],\n",
    "    'epochs': [100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tparam_grid=parameters, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tscoring='accuracy', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tcv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search = grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 Build the ANN Model for the Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Tune Next the Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 Build the ANN Model for the Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(X_train_sm.shape[1],)))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2 To Import gridSearchCV Class and Optimize the Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras classifier\n",
    "classifier = KerasClassifier(model=build_classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size=best_parameters['batch_size'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t epochs=best_parameters['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t param_grid=parameters, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t scoring='accuracy', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search = grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Tune Next the Optimizer's Learning Rate and Momentum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(X_train_sm.shape[1],)))\n",
    "    model.add(Dense(units=6, activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[38;5;241m=\u001b[39m KerasClassifier(model\u001b[38;5;241m=\u001b[39mbuild_classifier, \n\u001b[1;32m----> 2\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size\u001b[38;5;241m=\u001b[39m\u001b[43mbest_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[0;32m      3\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\t epochs\u001b[38;5;241m=\u001b[39mbest_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'batch_size'"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(model=build_classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size=best_parameters['batch_size'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t epochs=best_parameters['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    \"optimizer\": [\n",
    "        Adam(learning_rate=0.01),\n",
    "        Adam(learning_rate=0.001),\n",
    "        RMSprop(learning_rate=0.01, momentum=0.9),\n",
    "        RMSprop(learning_rate=0.001, momentum=0.9),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=classifier, param_grid=parameters, scoring=\"accuracy\", cv=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search = grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Tune Next the Network's Weight Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomNormal, HeNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(kernel_initializer='glorot_uniform'):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Input(shape=(X_train_sm.shape[1],), kernel_initializer=kernel_initializer)\n",
    "    )\n",
    "    model.add(Dense(units=6, activation=\"relu\", kernel_initializer=kernel_initializer))\n",
    "    model.add(\n",
    "        Dense(units=1, activation=\"sigmoid\", kernel_initializer=kernel_initializer)\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=best_parameters['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=build_classifier, batch_size=best_parameters['batch_size'], epochs=best_parameters['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'kernel_initializer': ['glorot_uniform', 'normal', HeNormal()]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t param_grid=parameters, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t scoring='accuracy', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search = grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tune Next the Neuron Activation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(activation='relu'):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(X_train_sm.shape[1],)))\n",
    "    model.add(Dense(units=6, activation=activation))\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer=best_parameters['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=build_classifier, batch_size=best_parameters['batch_size'], epochs=best_parameters['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'activation': ['relu', 'tanh', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=parameters, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Tune Next the Dropout Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1 Build the ANN Model for the Optimizer Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=6, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(units=6, activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=best_parameters['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=build_classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size=best_parameters['batch_size'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t epochs=best_parameters['epochs'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.2 To Import GridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=parameters, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Tune Next the Number of Neurons in the Hidden Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G.1 Build the ANN Model for the Optimizer Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(neurons=6):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=best_parameters['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=build_classifier, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t batch_size=best_parameters['batch_size'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t epochs=best_parameters['epochs'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G.1 Build the ANN Model for the Optimizer Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters\n",
    "parameters = {\n",
    "    'neurons': [6, 12, 24, 48, 64]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=parameters, scoring='accuracy', cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 - Use the New Improved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Build and Train the ANN Model with the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Making Predictions and evaluating the new ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform K-Fold Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Perform Hold-out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune to get the best parameters using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search = grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_parameters}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best parameters from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# train the Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestClassifier(**best_params)\n",
    "best_rf_model.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set results\n",
    "y_rf_pred = best_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_rf_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_rf_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_report = classification_report(y_test, y_rf_pred, zero_division=0)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(rf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.7354819691461137\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      7658\n",
      "           1       0.39      0.12      0.18      2519\n",
      "\n",
      "    accuracy                           0.74     10177\n",
      "   macro avg       0.58      0.53      0.51     10177\n",
      "weighted avg       0.67      0.74      0.68     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_gb_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_accuracy = accuracy_score(y_test, y_gb_pred)\n",
    "gb_report = classification_report(y_test, y_gb_pred, zero_division=0)\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {gb_accuracy}\")\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(gb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Confusion Matrix for Gradient Boosting Classifier\n",
    "gb_cm = confusion_matrix(y_test, y_gb_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    gb_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1]\n",
    ")\n",
    "plt.title(\"Gradient Boosting Classifier - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_xgb_pred)\n",
    "xgb_report = classification_report(y_test, y_xgb_pred, zero_division=0)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy}\")\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix for XGBoost Classifier\n",
    "xgb_cm = confusion_matrix(y_test, y_xgb_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    xgb_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1]\n",
    ")\n",
    "plt.title(\"XGBoost Classifier - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30458, number of negative: 30458\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2583\n",
      "[LightGBM] [Info] Number of data points in the train set: 60916, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb_model = LGBMClassifier()\n",
    "lgb_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_lgb_pred = lgb_model.predict(X_test)\n",
    "\n",
    "lgb_accuracy = accuracy_score(y_test, y_lgb_pred)\n",
    "lgb_report = classification_report(y_test, y_lgb_pred, zero_division=0)\n",
    "\n",
    "print(f\"LightGBM Accuracy: {lgb_accuracy}\")\n",
    "print(\"LightGBM Classification Report:\")\n",
    "print(lgb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix for LightGBM Classifier\n",
    "lgb_cm = confusion_matrix(y_test, y_lgb_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    lgb_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1]\n",
    ")\n",
    "plt.title(\"LightGBM Classifier - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30458, number of negative: 30458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2583\n",
      "[LightGBM] [Info] Number of data points in the train set: 60916, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Voting Classifier Accuracy: 0.7514984769578461\n",
      "Voting Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86      7658\n",
      "           1       0.49      0.07      0.12      2519\n",
      "\n",
      "    accuracy                           0.75     10177\n",
      "   macro avg       0.62      0.52      0.49     10177\n",
      "weighted avg       0.69      0.75      0.67     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Voting Classifier\n",
    "clf1 = GradientBoostingClassifier()\n",
    "clf2 = XGBClassifier()\n",
    "clf3 = LGBMClassifier()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[(\"gb\", clf1), (\"xgb\", clf2), (\"lgb\", clf3)], voting=\"soft\"\n",
    ")\n",
    "\n",
    "eclf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_eclf_pred = eclf.predict(X_test)\n",
    "\n",
    "eclf_accuracy = accuracy_score(y_test, y_eclf_pred)\n",
    "eclf_report = classification_report(y_test, y_eclf_pred, zero_division=0)\n",
    "\n",
    "print(f\"Voting Classifier Accuracy: {eclf_accuracy}\")\n",
    "print(\"Voting Classifier Classification Report:\")\n",
    "print(eclf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Confusion Matrix for Voting Classifier\n",
    "eclf_cm = confusion_matrix(y_test, y_eclf_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    eclf_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1]\n",
    ")\n",
    "plt.title(\"Voting Classifier - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
