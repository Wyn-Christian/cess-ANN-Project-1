{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTIFICIAL NEURAL NETWORK TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for numerical computation\n",
    "import pandas as pd # for data manipulation\n",
    "import matplotlib.pyplot as plt # for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. IMPORT THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "Y = dataset.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Data Information\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Encoding the Categorical Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 One-hot Encoding the \"Geography\" to Create Dummy Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "column_transformer = ColumnTransformer([(\"Geography\", OneHotEncoder(categories = \"auto\"), [1])], remainder=\"passthrough\")\n",
    "\n",
    "X = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2 Label Encoding the \"Gender\" Column to convert it to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X[:,4] = label_encoder.fit_transform(X[:,4])\n",
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Splitting the Dataset into Training Dataset & Testing Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=0, stratify=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Perform Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_standard = X_train.copy()\n",
    "X_test_standard = X_test.copy()\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train_standard)\n",
    "X_test_standard = standard_scaler.transform(X_test_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2. BUILDING THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Importing the Keras Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Initializing the ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Adding the Input Layer and the First Hidden Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = \"relu\", input_dim = 12 ))\n",
    "classifier.add(Dropout(rate = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Adding the Second Hidden Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = \"relu\"))\n",
    "classifier.add(Dropout(rate = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Adding the Output Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3. TRAINING THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Compiling the ANN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'sgd', loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fitting the ANN Model on the Training Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x = X_train_standard, y = Y_train, batch_size = 50, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Summarizing the ANN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4. MAKING PREDICTIONS AND EVALUATING THE ANN MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Predicting the Output of the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict_probability = classifier.predict(X_test_standard)\n",
    "Y_predict = np.rint(Y_predict_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. To Generate and Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(Y_test, Y_predict)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(confusion_matrix, annot = True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Expected Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Computing the Hold-Out Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(Y_test, Y_predict)\n",
    "print(\"Hold-out Accuracy\")\n",
    "print(accuracy)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Generating the Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, Y_predict))\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Predicting the Output of the Single Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geography: France\n",
    "# Credit Score: 600\n",
    "# Gender: Male\n",
    "# Age: 40 Years Old\n",
    "# Tenure: 3 Years\n",
    "# Balance: $ 60,000\n",
    "# Number of Products: 2\n",
    "# With Credit Card: Yes\n",
    "# Active Member: Yes\n",
    "# Estimated Salary: $ 50,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5: PERFORM K-FOLD CROSS-VALIDATION TO ASSESS THE PERFORMANCE OF THE ANN MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. To Feature Scale the X Variable Using the StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X.copy()\n",
    "X_standard = standard_scaler.fit_transform(X_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Build the ANN Classifier Using the KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier \n",
    "\n",
    "def classifier(): \n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = \"relu\", input_dim = 12 ))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = \"relu\"))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer = 'sgd', loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "ann_model = KerasClassifier(model = classifier, batch_size = 10, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Import the **StratifiedKFold** Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits = 10, shuffle = False, random_state = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Import the **cross_val_score** Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Try the following Performance Metrics\n",
    "    # A. accuracy, \"accuracy\"\n",
    "    # B. precision, \"precision\"\n",
    "    # C. recall, \"recall\"\n",
    "    # D. F1-score, \"f1\"\n",
    "    # E. ROC-AUC, \"roc_auc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Perform the k-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.1 Using **Accuracy** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = ann_model, X = X_standard, y = Y, cv = k_fold, scoring = \"accuracy\", n_jobs = 1)\n",
    "accuracies_average = accuracies.mean()\n",
    "accuracies_deviation = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"Accuracies of k-folds:\")\n",
    "print (accuracies)\n",
    "print (\"  \")\n",
    "print (\"Average Accuracy of k-folds:\")\n",
    "print (accuracies_average)\n",
    "print (\"  \")\n",
    "print (\"Accuracy Deviation of k-folds:\")\n",
    "print (accuracies_deviation)\n",
    "print (\"  \")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.2 Using **F1-Score** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = cross_val_score(estimator = ann_model, X = X_standard, y = Y, cv = k_fold, scoring = \"f1\", n_jobs = 1)\n",
    "f1_average = f1.mean()\n",
    "f1_deviation = f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"F1-Scores of k-folds:\")\n",
    "print (f1)\n",
    "print (\"  \")\n",
    "print (\"Average F1-Score of k-folds:\")\n",
    "print (f1_average)\n",
    "print (\"  \")\n",
    "print (\"F1-Score Deviation of k-folds:\")\n",
    "print (f1_deviation)\n",
    "print (\"  \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.3 Using **Precision** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = cross_val_score(estimator = ann_model, X = X_standard, y = Y, cv = k_fold, scoring = \"precision\", n_jobs = 1)\n",
    "precision_average = precision.mean()\n",
    "precision_deviation = precision.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Precision of k-folds:\")\n",
    "print (precision)\n",
    "print (\"  \")\n",
    "print (\"Average Precision of k-folds:\")\n",
    "print (precision_average)\n",
    "print (\"  \")\n",
    "print (\"Precision Deviation of k-folds:\")\n",
    "print (precision_deviation)\n",
    "print (\"  \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.4 Using **Recall** as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = cross_val_score(estimator = ann_model, X = X_standard, y = Y, cv = k_fold, scoring = \"recall\", n_jobs = 1)\n",
    "recall_average = recall.mean()\n",
    "recall_deviation = recall.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Recall of k-folds:\")\n",
    "print (recall)\n",
    "print (\"  \")\n",
    "print (\"Average Recall of k-folds:\")\n",
    "print (recall_average)\n",
    "print (\"  \")\n",
    "print (\"Recall Deviation of k-folds:\")\n",
    "print (recall_deviation)\n",
    "print (\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.5 Using ROC-AUC as the Scoring Metric for Cross-Valdiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = cross_val_score(estimator = ann_model, X = X_standard, y = Y, cv = k_fold, scoring = \"roc_auc\", n_jobs = 1)\n",
    "roc_auc_average = roc_auc.mean()\n",
    "roc_auc_deviation = roc_auc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"ROC-AUC of k-folds:\")\n",
    "print (roc_auc)\n",
    "print (\"  \")\n",
    "print (\"Average ROC-AUC of k-folds:\")\n",
    "print (roc_auc_average)\n",
    "print (\"  \")\n",
    "print (\"ROC-AUC Deviation of k-folds:\")\n",
    "print (roc_auc_deviation)\n",
    "print (\"  \")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 6. PERFORM HOLD-OUT VALIDATION TO ASSESS THE ARTIFICIAL NEURAL NETWORK MODEL'S PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion_matrix[1, 0]\n",
    "TN = confusion_matrix[0, 0]\n",
    "FP = confusion_matrix[0, 1]\n",
    "FN = confusion_matrix[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. For Classification Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(Y_test, Y_predict)\n",
    "print(\"Classification Accuracy: %.4f\"\n",
    "      %classification_accuracy)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. For Classification Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_error = 1 - classification_accuracy\n",
    "print(\"Classification Error: %.4f\"\n",
    "      %classification_error)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. For the Sensitivity, Recall Score, Probability of Detection, True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(Y_test, Y_predict, average = \"weighted\")\n",
    "print(\"Recall Score: %.4f\"\n",
    "      %recall)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. For the Specificity or True Negative Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Specificity = TN / (TN + FP)\n",
    "print(\"Specificity: %.4f\"\n",
    "      %Specificity)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. For the False Positive Rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = 1 - Specificity\n",
    "print(\"False Positive Rate: %.4f\"\n",
    "      %false_positive_rate)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. For the Precision or Positive Predictive Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(Y_test, Y_predict, average = \"weighted\")\n",
    "print(\"Precision Score: %.4f\"\n",
    "      %precision)\n",
    "print (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. For the F1-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(Y_test, Y_predict, average = \"weighted\")\n",
    "print(\"F1-Score: %.4f\" %f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. For the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report = classification_report(Y_test, Y_predict)\n",
    "\n",
    "print (classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. For the Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision_value, recall_value, threshold = precision_recall_curve(Y_test, Y_predict)\n",
    "\n",
    "plt.plot(precision_value, recall_value)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title (\"Precision Recall Curve for the ANN Model\")\n",
    "plt.xlabel (\"Precision\")\n",
    "plt.ylabel(\"Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J. For the ROC Curve with AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.1 For the Receiver Operating Curve (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "FPR, TPR, threshold = roc_curve(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.2 For the Area Under the Curve (AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "AUC_score = roc_auc_score(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.3 To Plot the ROC Curve with AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR, label = \"ROC Curve\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J.4 For the Plot of Baseline for AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label = \"Baseline\", linestyle = \"--\")\n",
    "plt.title (f\"ROC Curve with AUC = {round(AUC_score, 4)}), for the ANN Model\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 7. PERFORM HYPERPARAMETER TUNING TO OPTIMIZE THE ARTIFICIAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Tune First the Batch Size and Epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(optimizer = \"sgd\"):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = \"relu\", input_dim = 12 )) \n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = \"relu\" ))\n",
    "    classifier_optimization.add(Dense(units = 1 , kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\" ))\n",
    "    classifier_optimization.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.2 To Import gridSearchCV Class and Optimize the Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Set Parameters to be Optimized for the ANN Model\n",
    "parameters = {\"batch_size\": [50, 100, 200, 500],\n",
    "              \"epochs\": [100, 150, 200, 250]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = k_fold,\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\"  \")\n",
    "\n",
    "print (\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Tune Next the Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 Build the ANN Model for the Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(optimizer = \"sgd\"):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = \"relu\", input_dim = 12 )) \n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = \"relu\" ))\n",
    "    classifier_optimization.add(Dense(units = 1 , kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\" ))\n",
    "    classifier_optimization.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, batch_size = 50, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Set Parameters to be Optimized for the ANN Model\n",
    "# parameters =  {'optimizer': ['adam', 'sgd', 'rmsprop', 'adamW', 'adadelta', 'adagrad', 'adamax', 'adafactor', 'aadam', 'ftrl', 'Lion', 'LossScaleOptimizer']}\n",
    "\n",
    "parameters =  {'optimizer': ['adam', 'sgd', 'rmsprop', 'adamW', 'ftrl', ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = k_fold,\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\"  \")\n",
    "\n",
    "print (\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Tune Next the Optimizer's Learning Rate and Momentum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(learning_rate, momentum):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = \"relu\", input_dim = 12 )) \n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = \"relu\" ))\n",
    "    classifier_optimization.add(Dense(units = 1 , kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\" ))\n",
    "    optimizer_setting = RMSprop(learning_rate = learning_rate, momentum = momentum)\n",
    "    classifier_optimization.compile(optimizer = optimizer_setting, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, learning_rate = 0.001, momentum = 0.0, batch_size = 50, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Set Parameters to be Optimized for the ANN Model\n",
    "parameters =  {'learning_rate': [0.001, 0.01, 0.1, 1.0], 'momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = k_fold,\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\"  \")\n",
    "\n",
    "print (\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Parameters {'batch_size': 50, 'epochs':200}\n",
    "#Best Parameters {'optimizer': rmsprop'}\n",
    "#Best Parameters {'learning_rate': 0.001, 'momentum':0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Tune Next the Network's Weight Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(kernel_initializer):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer = kernel_initializer, activation = \"relu\", input_dim = 12 )) \n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer = kernel_initializer, activation = \"relu\" ))\n",
    "    classifier_optimization.add(Dense(units = 1 , kernel_initializer = kernel_initializer, activation = \"sigmoid\" ))\n",
    "    optimizer_setting = RMSprop(learning_rate = 0.001, momentum = 0.2)\n",
    "    classifier_optimization.compile(optimizer = optimizer_setting, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, kernel_initializer = \"glorot_uniform\", batch_size = 50, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Set Parameters to be Optimized for the ANN Model\n",
    "# parameters = {'kernel_initializer': ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']}\n",
    "\n",
    "parameters = {'kernel_initializer': ['uniform', 'normal', 'zero', 'glorot_uniform']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = k_fold,\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\"  \")\n",
    "\n",
    "print (\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters {'batch_size': 50, 'epochs':200}\n",
    "# Best Parameters {'optimizer': rmsprop'}\n",
    "# Best Parameters {'learning_rate': 0.001, 'momentum':0.2}\n",
    "# Best Parameters {\"kernel_initializer': glorot_uniform}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tune Next the Neuron Activation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.1 Build the ANN Model for the Optimization Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(activation1, activation2, activation3):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer = \"glorot_uniform\", activation = activation1, input_dim = 12 )) \n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer = \"glorot_uniform\", activation = activation2 ))\n",
    "    classifier_optimization.add(Dense(units = 1 , kernel_initializer = \"glorot_uniform\", activation = activation3 ))\n",
    "    optimizer_setting = RMSprop(learning_rate = 0.001, momentum = 0.2)\n",
    "    classifier_optimization.compile(optimizer = optimizer_setting, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, activation1 = \"relu\", activation2 = \"relu\", activation3 = \"relu\", batch_size = 50, epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.2 To Import gridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Set Parameters to be Optimized for the ANN Model\n",
    "\n",
    "#parameters = {'activation1': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "#              'activation2': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "#              'activation3': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']}\n",
    "\n",
    "parameters = {'activation1': ['softmax', 'relu', 'tanh', 'sigmoid'],\n",
    "              'activation2': ['softmax', 'relu', 'tanh', 'sigmoid'],\n",
    "              'activation3': ['softmax', 'relu', 'tanh', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, \n",
    "                           param_grid = parameters, \n",
    "                           scoring = \"accuracy\",\n",
    "                           cv = k_fold,\n",
    "                           n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridSearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\"  \")\n",
    "\n",
    "print (\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters {'batch_size': 50, 'epochs':200}\n",
    "# Best Parameters {'optimizer': rmsprop'}\n",
    "# Best Parameters {'learning_rate': 0.001, 'momentum':0.2}\n",
    "# Best Parameters {\"kernel_initializer': glorot_uniform}\n",
    "# Best Parameters {'activation1': 'relu', 'activation2': 'sigmoid' , 'activation3': 'sigmoid'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Tune Next the Dropout Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.1 Build the ANN Model for the Optimizer Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import MaxNorm\n",
    "\n",
    "def classifier_optimization(dropout_rate, weight_constraint):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = 7, kernel_initializer=\"glorot_uniform\", activation = 'relu', kernel_constraint=MaxNorm(weight_constraint), input_dim = 12))\n",
    "    classifier_optimization.add(Dropout(rate=dropout_rate))\n",
    "    classifier_optimization.add(Dense(units = 6, kernel_initializer=\"glorot_uniform\", activation = 'relu', kernel_constraint=MaxNorm(weight_constraint)))\n",
    "    classifier_optimization.add(Dropout(rate=dropout_rate))\n",
    "    classifier_optimization.add(Dense(units = 1, kernel_initializer=\"glorot_uniform\", activation = 'sigmoid', kernel_constraint=MaxNorm(weight_constraint)))\n",
    "    classifier_optimization.add(Dropout(rate=dropout_rate))\n",
    "    optimizer_setting = RMSprop(learning_rate = 0.001, momentum = 0.9)\n",
    "    classifier_optimization.compile(optimizer = optimizer_setting, loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, dropout_rate = 0.0, weight_constraint = 0.5, batch_size = 50, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.2 To Import GridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridsearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'weight_constraint': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "              'dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridsearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, param_grid = parameters, scoring = \"accuracy\", cv = k_fold, n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridsearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"params\"]]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Tune Next the Number of Neurons in the Hidden Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G.1 Build the ANN Model for the Optimizer Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_optimization(neuron1, neuron2):\n",
    "    classifier_optimization = Sequential()\n",
    "    classifier_optimization.add(Dense(units = neuron1, kernel_initializer=\"glorot_uniform\", activation = 'relu', kernel_constraint=MaxNorm(2.0), input_dim = 12))\n",
    "    classifier_optimization.add(Dropout(rate=0.0))\n",
    "    classifier_optimization.add(Dense(units = neuron2, kernel_initializer=\"glorot_uniform\", activation = 'relu', kernel_constraint=MaxNorm(2.0)))\n",
    "    classifier_optimization.add(Dropout(rate=0.0))\n",
    "    classifier_optimization.add(Dense(units = 1, kernel_initializer=\"glorot_uniform\", activation = 'sigmoid', kernel_constraint=MaxNorm(2.0)))\n",
    "    classifier_optimization.add(Dropout(rate=0.0))\n",
    "    optimizer_setting = RMSprop(learning_rate = 0.001, momentum = 0.9)\n",
    "    classifier_optimization.compile(optimizer = optimizer_setting, loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return classifier_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model_optimization = KerasClassifier(model = classifier_optimization, neuron1 = 10, neuron2 = 10, batch_size = 50, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G.2 To Import GridSearchCV Class and Optimize the Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Import the GridsearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'neuron1': [10, 15, 20, 25, 30],\n",
    "              'neuron2': [10, 15, 20, 25, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Define the GridsearchCV\n",
    "grid_search = GridSearchCV(estimator = ann_model_optimization, param_grid = parameters, scoring = \"accuracy\", cv = k_fold, n_jobs = 1)\n",
    "grid_search = grid_search.fit(X_standard, Y)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To View the Results of the GridsearchCV\n",
    "results = pd.DataFrame(grid_search.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"params\"]]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Identify the Best Accuracy and the Best Parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Accuracy Score\")\n",
    "print(best_accuracy)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Best Parameters\")\n",
    "print(best_parameters)\n",
    "print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
